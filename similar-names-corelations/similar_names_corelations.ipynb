{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-size:22pt;font-family:'Ubuntu';\">Similar Names Corelations</p>\n",
    "\n",
    "<br>\n",
    "\n",
    "This document is to present corelations between polish names based on their similarity. The data comes from external file (in this case xlsx sheet which contains **16417 rows and 4 columns** about ranking of popular polish names) which will be loaded and used in this workbook. The result will be presened in a [Directed graph](https://en.wikipedia.org/wiki/Directed_graph) as a hierarchy of particular similar groups. \n",
    "\n",
    "The algorithm is simple - we decide which names are should be grupped together in a hierarchy based on how much cost(insertion, deletion, substitution of particular letters in a word) it takes to get desired similarity. \n",
    "\n",
    "Similarity is measured by [Gaussian Kernel algorithm](http://mccormickml.com/2013/08/15/the-gaussian-kernel/) which allows us to perform [Affinity Propagation](https://en.wikipedia.org/wiki/Affinity_propagation) on the data and then create hierarchy groups based on the similarity.\n",
    "\n",
    "\n",
    "list of modules used in this worksheet includes **openpyxl** to load xlsx file,\n",
    "**pandas** to work on out file (DataFrame),\n",
    "**matplotlib** for gaussian kernel graphical demonstration,\n",
    "**sklearn.cluster** to clusterize our words based on costs,\n",
    "**graphviz** - to draw result as a directed graph, \n",
    "python built in libraries **collections** (default dict) and **itertools** (product, permutations), \n",
    "and ultimately of course, **numpy**;\n",
    "\n",
    "this worksheet was created with help of Paweł Wołoszyn\n",
    "\n",
    "note: sometimes graphviz has a problem with rendering results inside jupyter. If you come across this kind of trouble, check this project directory, images will be stored there eventually.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some lines are hidden due to better readability. To show hidden result remove ';' from the end of the command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook = load_workbook('names.xlsx')\n",
    "workbook.sheetnames;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet = workbook.active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" play with worksheet \"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worksheet.calculate_dimension()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(worksheet.values)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(worksheet.values)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(worksheet.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(worksheet.column_dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(worksheet.values)[10][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.read_excel('names.xlsx');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head_row, *rows = worksheet.values\n",
    "head_row;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" load our data into the workhorse \"\"\"\n",
    "names_data = pd.DataFrame(rows, columns=head_row) \n",
    "names_data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_data.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_data['Płeć'][3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" return unique values of names_data. Its does not sort values \"\"\"\n",
    "\n",
    "uniques = names_data['Imię'].unique();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" group data by name column and return total number of occurences\"\"\"\n",
    "\n",
    "grouped_names = names_data[['Imię', 'Liczba']].groupby('Imię')\n",
    "len(uniques) == len(grouped_names);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" ranking of unique gruped names \"\"\"\n",
    "\n",
    "grouped_ranking = grouped_names.sum().sort_values(by='Liczba', ascending=False)\n",
    "grouped_ranking;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = grouped_ranking.index[:300].values\n",
    "test_names = names[:10]\n",
    "test_names;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLISH_ALPHABET = 'AĄBCĆDEĘFGHIJKLŁMNŃOÓPQRSŚTUVWXYZŹŻ'\n",
    "POLISH_VOWELS = 'AĄEĘIOÓUY'\n",
    "POLISH_SIMILAR = ['CĆ', 'IJY', 'LŁ', 'NŃ', 'OÓU', 'SŚ', 'VW', 'ZŹŻ']\n",
    "POLISH_LESS_SIMILAR = ['BP', 'GK', 'FH', 'MN', 'CKX', 'CSZ']\n",
    "POLISH_PAIRS = ['CH', 'GH', 'PH', 'SH', \n",
    "                'CZ', 'DZ', 'RZ', 'SZ',\n",
    "                'IA', 'IE', 'II', 'IO', 'IU',\n",
    "                'CI', 'NI', 'SI', 'ZI',\n",
    "                'JJ', 'KK', 'LL', 'ŁŁ', 'MM', 'NN', 'PP', 'RR', 'SS', 'ZZ',\n",
    "                'CS', 'KS', 'PS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POLISH_LESS_SIMILAR_COST = 0.6\n",
    "POLISH_SIMILAR_COST = 0.4\n",
    "POLISH_VOWELS_SUBSTITUTION_COST = 0.2\n",
    "\n",
    "POLISH_VOWELS_INDEL_COST = 1.5\n",
    "POLISH_PAIR_COST = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "class PairsCosts(defaultdict):\n",
    "    \"\"\" class for making costs of words pairs \"\"\"\n",
    "    \n",
    "    def __init__(self, default_cost=1):\n",
    "        \"\"\" this is pretty much the same as dict build in type, but sets default cost to 1 if not provided \"\"\"\n",
    "        super().__init__(lambda: defaultdict(lambda:default_cost))\n",
    "        \n",
    "    def set_pairs(self, iterable, cost):\n",
    "        \"\"\" set cost of a pair only in a polish pair group \"\"\"\n",
    "        \n",
    "        for first, second in iterable:\n",
    "            self[first][second] = cost\n",
    "            \n",
    "    def set_reflexive(self, iterable, cost):\n",
    "        \"\"\" set cost of the same letter \"\"\"\n",
    "        \n",
    "        for item in iterable:\n",
    "            self[item][item] = cost\n",
    "            \n",
    "    def set_cliques(self, cliques, cost):\n",
    "        \"\"\" set cost of a pair in groups \"\"\"\n",
    "        \n",
    "        from itertools import permutations\n",
    "        for clique in cliques:\n",
    "            for first, second in permutations(clique, 2):\n",
    "                self[first][second] = cost\n",
    "     \n",
    "    def set_product (self, first_iterable, second_iterable, cost):\n",
    "        \"\"\" set costs as a cartesian product of two iterables \"\"\"\n",
    "        \n",
    "        from itertools import product\n",
    "        for first, second in product(first_iterable, second_iterable):\n",
    "            self[first][second] = cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitution_costs (alphabet, similarity_groups):\n",
    "    \"\"\" calculate substitution costs for each subgroup \"\"\"\n",
    "    \n",
    "    costs = PairsCosts()\n",
    "    for subgroups, cost in similarity_groups:\n",
    "        costs.set_cliques(subgroups, cost)\n",
    "    costs.set_reflexive(alphabet, 0)\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indel_costs (alphabet, single_groups, pair_groups):\n",
    "    \"\"\" calculate cartesian product for vowels and pair costs for pairs \"\"\"\n",
    "    \n",
    "    costs = PairsCosts()\n",
    "    for group, cost in single_groups:\n",
    "        costs.set_product(alphabet, group, cost)\n",
    "    for group, cost in pair_groups:\n",
    "        costs.set_pairs(group, cost)\n",
    "    return costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_indel_costs = indel_costs(POLISH_ALPHABET, \n",
    "                                 [(POLISH_VOWELS, POLISH_VOWELS_INDEL_COST)], \n",
    "                                 [(POLISH_PAIRS, POLISH_PAIR_COST)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_substitution_costs = substitution_costs(POLISH_ALPHABET, \n",
    "                                               [(POLISH_SIMILAR, POLISH_SIMILAR_COST), \n",
    "                                               (POLISH_LESS_SIMILAR, POLISH_LESS_SIMILAR_COST),\n",
    "                                               ([POLISH_VOWELS], POLISH_VOWELS_SUBSTITUTION_COST)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" check costs of some groups \"\"\"\n",
    "\n",
    "polish_substitution_costs['Z'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polish_indel_costs['Z'].items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(source, target, substitution_costs=None, \n",
    "                       indel_costs=None, force_symmetric=True):\n",
    "    \n",
    "    \"\"\" returns minimum distance as a float point number based on costs to get from source to target \"\"\"\n",
    "    \n",
    "    source_lengths = len(source) + 1 \n",
    "    target_lengths = len(target) + 1\n",
    "    \n",
    "    distances = np.zeros((source_lengths, target_lengths)) # initialize two dimension array full of 0 as a distance\n",
    "    distances[0, :] = range(target_lengths)\n",
    "    distances[:, 0] = range(source_lengths)\n",
    "    \n",
    "    for s in range(1, source_lengths):\n",
    "        for t in range(1, target_lengths):\n",
    "            \n",
    "            insertion = 1 \n",
    "            deletion = 1\n",
    "            \n",
    "            source_prefix = source[:s]\n",
    "            target_prefix = target[:t]\n",
    "            \n",
    "            if indel_costs is not None:\n",
    "                deletion = indel_costs[target_prefix[-1]][source_prefix[-1]]\n",
    "                if t > 1:\n",
    "                    insertion = indel_costs[target_prefix[-2]][target_prefix[-1]]\n",
    "                \n",
    "            if substitution_costs is not None:\n",
    "                substitution = substitution_costs[source_prefix[-1]][target_prefix[-1]]\n",
    "            else:\n",
    "                substitution = 0 if target_prefix[-1] == source_prefix[-1] else 1\n",
    "    \n",
    "            distances[s, t] = min(\n",
    "                distances[s-1, t] + deletion,\n",
    "                distances[s, t-1] + insertion,\n",
    "                distances[s-1, t-1] + substitution\n",
    "            )\n",
    "\n",
    "    result = distances[-1, -1]\n",
    "    if force_symmetric:\n",
    "        reverse_result = calculate_distance(target, source, \n",
    "                                       substitution_costs, indel_costs, \n",
    "                                       force_symmetric=False)\n",
    "        result = (result + reverse_result) / 2\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distance('OLA', 'ANIA');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_distance('MIECZYSŁAW', 'HUNEGUNDA');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_word(alphabet, minl, maxl):\n",
    "    from random import randint, choices\n",
    "    length = randint(minl, maxl)\n",
    "    return ''.join(choices(alphabet, k=length))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_word(POLISH_ALPHABET, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" tests \"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "class TestEditDistance (unittest.TestCase):\n",
    "    \n",
    "    def word (self):\n",
    "        return random_word(POLISH_ALPHABET, 5, 10)\n",
    "    def metric (self, first, second):\n",
    "        return calculate_distance(first, second, polish_substitution_costs, polish_indel_costs)\n",
    "    \n",
    "    def test_nonnegativity (self):\n",
    "        for n in range(100):\n",
    "            distance = self.metric(self.word(), self.word())\n",
    "            self.assertGreaterEqual(distance, 0)\n",
    "            \n",
    "    def test_symmetry (self):\n",
    "        for n in range(100):\n",
    "            x, y = self.word(), self.word()\n",
    "            distance = self.metric(x, y)\n",
    "            reverse_distance = self.metric(y, x)\n",
    "            self.assertEqual(distance, reverse_distance)\n",
    "            \n",
    "    def test_identity (self):\n",
    "        for n in range(100):\n",
    "            w = self.word()\n",
    "            distance = self.metric(w, w)\n",
    "            self.assertEqual(distance, 0)\n",
    "\n",
    "    def test_triangle_inequality (self):\n",
    "        for n in range(100):\n",
    "            x, y, z = self.word(), self.word(), self.word()\n",
    "            straight_distance = self.metric(x, z)\n",
    "            through_distance = self.metric(x, y) + self.metric(y, z)\n",
    "            self.assertGreaterEqual(through_distance, straight_distance)\n",
    "\n",
    "unittest.main(argv=[''], exit=False, verbosity=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_kernel(x, delta=None):\n",
    "    \"\"\" gaussian kernel algorithm to calculate similarity between two words \"\"\"\n",
    "    \n",
    "    return np.exp(-x**2 / (2 * (delta or x.std())**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.linspace(0, 10, num=51)\n",
    "plt.plot(x, gaussian_kernel(x));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_matrix (words: np.array, substitution_costs=None, indel_costs=None):\n",
    "    \"\"\" returns similarity between two words as a 0-1 float point number  \"\"\"\n",
    "    \n",
    "    def distance (i, j):\n",
    "        return calculate_distance(words[i], words[j], substitution_costs, indel_costs)\n",
    "    vectorized_distance = np.vectorize(distance)\n",
    "    print(vectorized_distance)\n",
    "    distances = np.fromfunction(vectorized_distance, words.shape * 2, dtype=int)\n",
    "    return gaussian_kernel(distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = affinity_matrix(test_names, polish_substitution_costs, polish_indel_costs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.array_repr(similarity)); # similarity for each word in test_names, determined by gaussian kernel algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clusterize (words: np.array, substitution_costs=None, indel_costs=None):\n",
    "    \"\"\"perform affinity propagation clustering on names data \"\"\"\n",
    "    \n",
    "    from sklearn.cluster import AffinityPropagation\n",
    "    classifier = AffinityPropagation(affinity='precomputed')\n",
    "    affinities = affinity_matrix(words, substitution_costs, indel_costs)\n",
    "    clustering = classifier.fit_predict(affinities)\n",
    "    exemplars = classifier.cluster_centers_indices_\n",
    "    return clustering, exemplars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groups (words, substitution_costs=None, indel_costs=None):\n",
    "    \"\"\" create clusterized groups based on similarity\"\"\"\n",
    "    \n",
    "    words = np.array(words)\n",
    "    clusters, exemplars = clusterize(words, substitution_costs, indel_costs)\n",
    "    def cluster (n):\n",
    "        exemplar = exemplars[n]\n",
    "        indices = np.where(clusters == n)[0]\n",
    "        members = indices[indices != exemplar]\n",
    "        return words[exemplar], list(words[members])\n",
    "    return dict(cluster(n) for n in range(len(exemplars)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups(test_names, polish_substitution_costs, polish_indel_costs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hierarchy_groups (words, substitution_costs=None, indel_costs=None):\n",
    "    \"\"\" create hierarchy groups based on clusterized similar groups \"\"\"\n",
    "    \n",
    "    hierarchy = {word: {} for word in words}\n",
    "    old_len, new_len = None, len(hierarchy)\n",
    "    while old_len != new_len and new_len > 1:\n",
    "        words = list(hierarchy.keys())\n",
    "        grouping = groups(words, substitution_costs, indel_costs)\n",
    "        for exemplar, members in grouping.items():\n",
    "            for member in members:\n",
    "                member_group = hierarchy.pop(member)\n",
    "                hierarchy[exemplar][member] = member_group\n",
    "        old_len, new_len = new_len, len(hierarchy)\n",
    "    return hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from graphviz import Graph, Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate (graph, hierarchy):\n",
    "    \"\"\" add nodes and edges to graph \"\"\"\n",
    "    \n",
    "    for key, subdict in hierarchy.items():\n",
    "        graph.node(key)\n",
    "        for subkey in subdict:\n",
    "            graph.edge(key, subkey)\n",
    "        populate(graph, subdict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Digraph(engine='sfdp')\n",
    "hierarchy = hierarchy_groups(names, polish_substitution_costs, polish_indel_costs)\n",
    "populate(graph, hierarchy)\n",
    "graph.attr(overlap='false', splines='true')\n",
    "graph.render('names', view=False) #display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
